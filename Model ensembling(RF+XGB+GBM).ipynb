{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1554e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "import seaborn as snss\n",
    "import missingno as msno\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from scipy.stats import boxcox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3ab5ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('train_final.csv')\n",
    "df_test=pd.read_csv('test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "831912f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16383, 26)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "target=df_train.Y\n",
    "df_train.drop('Y',axis='columns',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae41cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[df_train,df_test]\n",
    "df=pd.concat(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba64bb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16385,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID=df.Id\n",
    "df1=df.drop('Id',axis='columns')\n",
    "test_ID=ID[16383:]\n",
    "test_ID.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d5fdd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler((0,1))\n",
    "#scaler = StandardScaler()\n",
    "#scaler = PowerTransformer()\n",
    "#scaler = QuantileTransformer()\n",
    "#scaler = RobustScaler()\n",
    "#scaler=MaxAbsScaler()\n",
    "df2=np.array(df1)\n",
    "scaler.fit(df2[:16383])\n",
    "df3=scaler.transform(df2)\n",
    "Norm_df=pd.DataFrame(df3)\n",
    "#Norm_df=df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb532775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8129</th>\n",
       "      <td>0.140114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.359379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370395</td>\n",
       "      <td>0.368604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008243</td>\n",
       "      <td>0.410240</td>\n",
       "      <td>0.942199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.946961e-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11743</th>\n",
       "      <td>0.083264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.357870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370203</td>\n",
       "      <td>0.448511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170452</td>\n",
       "      <td>0.440458</td>\n",
       "      <td>0.377379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005072</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.830376e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11536</th>\n",
       "      <td>0.090859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.359482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370395</td>\n",
       "      <td>0.401209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052039</td>\n",
       "      <td>0.409914</td>\n",
       "      <td>0.942199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.805641e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10017</th>\n",
       "      <td>0.113720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.359379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370395</td>\n",
       "      <td>0.753801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009927</td>\n",
       "      <td>0.409892</td>\n",
       "      <td>0.378164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.473480e-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7369</th>\n",
       "      <td>0.080851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.359543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370395</td>\n",
       "      <td>0.376195</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055302</td>\n",
       "      <td>0.404650</td>\n",
       "      <td>0.375706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.657181e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16127</th>\n",
       "      <td>0.118419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.359216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371356</td>\n",
       "      <td>0.404985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049257</td>\n",
       "      <td>0.403905</td>\n",
       "      <td>0.948341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>0.074089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.359094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370395</td>\n",
       "      <td>0.408410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024260</td>\n",
       "      <td>0.403126</td>\n",
       "      <td>0.377559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>0.024597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.359094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370395</td>\n",
       "      <td>0.520202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055725</td>\n",
       "      <td>0.408010</td>\n",
       "      <td>0.875309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.452265e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.012343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.359706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370395</td>\n",
       "      <td>0.813964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056364</td>\n",
       "      <td>0.415737</td>\n",
       "      <td>0.375706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.420441e-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13349</th>\n",
       "      <td>0.106489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.358121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370395</td>\n",
       "      <td>0.380821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346798</td>\n",
       "      <td>0.405135</td>\n",
       "      <td>0.377379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.473480e-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16383 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0    1        2         3    4    5         6         7    8   \\\n",
       "8129   0.140114  0.0  0.00000  0.359379  0.0  0.0  0.370395  0.368604  0.0   \n",
       "11743  0.083264  0.0  0.00004  0.357870  0.0  0.0  0.370203  0.448511  0.0   \n",
       "11536  0.090859  0.0  0.00000  0.359482  0.0  0.0  0.370395  0.401209  0.0   \n",
       "10017  0.113720  0.0  0.00000  0.359379  0.0  0.0  0.370395  0.753801  0.0   \n",
       "7369   0.080851  0.0  0.00000  0.359543  0.0  0.0  0.370395  0.376195  0.1   \n",
       "...         ...  ...      ...       ...  ...  ...       ...       ...  ...   \n",
       "16127  0.118419  0.0  0.00000  0.359216  0.0  0.0  0.371356  0.404985  0.0   \n",
       "5192   0.074089  0.0  0.00000  0.359094  0.0  0.0  0.370395  0.408410  0.0   \n",
       "12172  0.024597  0.0  0.00004  0.359094  0.0  0.0  0.370395  0.520202  0.0   \n",
       "235    0.012343  0.0  0.00004  0.359706  0.0  0.0  0.370395  0.813964  0.0   \n",
       "13349  0.106489  0.0  0.00004  0.358121  0.0  0.0  0.370395  0.380821  0.0   \n",
       "\n",
       "             9   ...        14        15        16   17        18        19  \\\n",
       "8129   0.000000  ...  0.008243  0.410240  0.942199  0.0  0.000134  0.000000   \n",
       "11743  0.000000  ...  0.170452  0.440458  0.377379  0.0  0.005072  0.285714   \n",
       "11536  0.000000  ...  0.052039  0.409914  0.942199  0.0  0.014491  0.000000   \n",
       "10017  0.000000  ...  0.009927  0.409892  0.378164  0.0  0.010155  0.000000   \n",
       "7369   0.000199  ...  0.055302  0.404650  0.375706  0.0  0.000902  0.000000   \n",
       "...         ...  ...       ...       ...       ...  ...       ...       ...   \n",
       "16127  0.000794  ...  0.049257  0.403905  0.948341  0.0  0.005753  0.000000   \n",
       "5192   0.000000  ...  0.024260  0.403126  0.377559  0.0  0.002949  0.000000   \n",
       "12172  0.000199  ...  0.055725  0.408010  0.875309  0.0  0.001691  0.000000   \n",
       "235    0.000596  ...  0.056364  0.415737  0.375706  0.0  0.002521  0.000000   \n",
       "13349  0.000000  ...  0.346798  0.405135  0.377379  0.0  0.014269  0.000000   \n",
       "\n",
       "        20   21            22   23  \n",
       "8129   0.0  0.0  4.946961e-09  0.0  \n",
       "11743  0.0  0.0  1.830376e-07  0.0  \n",
       "11536  0.0  0.0  1.805641e-07  0.0  \n",
       "10017  0.0  0.0  2.473480e-09  0.0  \n",
       "7369   0.0  0.0  8.657181e-08  0.0  \n",
       "...    ...  ...           ...  ...  \n",
       "16127  0.0  0.0  0.000000e+00  0.0  \n",
       "5192   0.0  0.0  0.000000e+00  0.0  \n",
       "12172  0.0  0.0  4.452265e-08  0.0  \n",
       "235    0.0  0.0  7.420441e-09  0.0  \n",
       "13349  0.0  0.0  2.473480e-09  0.0  \n",
       "\n",
       "[16383 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Norm_df_train=Norm_df[:16383]\n",
    "shuffle(Norm_df_train, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a6ea5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Norm_df_test=Norm_df[16383:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddcc97c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb44524b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:19:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:19:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:19:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:19:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:19:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8756546506098959\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "warnings.filterwarnings('ignore')\n",
    "alphas = [400]\n",
    "for i in alphas:\n",
    "    model_xgb=  XGBClassifier(n_estimators=i,\n",
    "                              base_score=0.1,\n",
    "                              booster='gbtree',\n",
    "                              colsample_bylevel=1,\n",
    "                              colsample_bynode=1,\n",
    "                              gamma=0,\n",
    "                              learning_rate=0.3,\n",
    "                              max_delta_step=0,\n",
    "                              max_depth=6,\n",
    "                              min_child_weight=1,\n",
    "                              n_jobs=8,\n",
    "                              reg_alpha=0,\n",
    "                              reg_lambda=1,\n",
    "                              scale_pos_weight=1,\n",
    "                              random_state=0)\n",
    "    n_scores = cross_val_score(model_xgb, Norm_df_train, target, scoring='roc_auc', cv=5).mean()\n",
    "    print(n_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa4c2746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:20:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.1, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.3, max_delta_step=0,\n",
       "              max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=800, n_jobs=8,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_model=  XGBClassifier(n_estimators=400,\n",
    "                              base_score=0.1,\n",
    "                              booster='gbtree',\n",
    "                              colsample_bylevel=1,\n",
    "                              colsample_bynode=1,\n",
    "                              gamma=0,\n",
    "                              learning_rate=0.3,\n",
    "                              max_delta_step=0,\n",
    "                              max_depth=6,\n",
    "                              min_child_weight=1,\n",
    "                              n_jobs=8,\n",
    "                              reg_alpha=0,\n",
    "                              reg_lambda=1,\n",
    "                              scale_pos_weight=1,\n",
    "                              random_state=0)\n",
    "sub_model.fit(Norm_df_train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1668534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9939838 , 0.9980069 , 1.        , ..., 0.9999995 , 0.99771464,\n",
       "       0.9983796 ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h=sub_model.predict_proba(Norm_df_test)\n",
    "y_newpred=h[:,1]\n",
    "y_newpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06395413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8832868677831426\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "alphas = [500] \n",
    "for i in alphas:\n",
    "    model_randomforest= RandomForestClassifier(n_estimators=i,\n",
    "                                               max_features='auto',\n",
    "                                               min_samples_leaf=2,\n",
    "                                               min_samples_split=2,\n",
    "                                               max_depth=50,\n",
    "                                               min_weight_fraction_leaf=0,\n",
    "                                               max_leaf_nodes=1000,\n",
    "                                               criterion='entropy',\n",
    "                                               min_impurity_decrease=0,\n",
    "                                               n_jobs=1,\n",
    "                                               class_weight='balanced_subsample',\n",
    "                                               ccp_alpha=0,\n",
    "                                               random_state=0)\n",
    "    n_scores = cross_val_score(model_randomforest, Norm_df_train, target, scoring='roc_auc', cv=5).mean()\n",
    "    print(n_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "32853ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(ccp_alpha=0, class_weight='balanced_subsample',\n",
       "                       criterion='entropy', max_depth=50, max_leaf_nodes=1000,\n",
       "                       min_impurity_decrease=0, min_samples_leaf=2,\n",
       "                       min_weight_fraction_leaf=0, n_estimators=500, n_jobs=1,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_rfmodel=RandomForestClassifier(n_estimators=500,\n",
    "                                               max_features='auto',\n",
    "                                               min_samples_leaf=2,\n",
    "                                               min_samples_split=2,\n",
    "                                               max_depth=50,\n",
    "                                               min_weight_fraction_leaf=0,\n",
    "                                               max_leaf_nodes=1000,\n",
    "                                               criterion='entropy',\n",
    "                                               min_impurity_decrease=0,\n",
    "                                               n_jobs=1,\n",
    "                                               class_weight='balanced_subsample',\n",
    "                                               ccp_alpha=0,\n",
    "                                               random_state=0)\n",
    "sub_rfmodel.fit(Norm_df_train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d16c7430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82328834, 0.6861963 , 0.98372147, ..., 0.99811793, 0.91052192,\n",
       "       0.87437623])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1=sub_rfmodel.predict_proba(Norm_df_test)\n",
    "y_newpred1=h1[:,1]\n",
    "y_newpred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "736ff999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8610617931648399\n",
      "0.8652238467889841\n",
      "0.8667171816811223\n",
      "0.8702866694144207\n",
      "0.871583466819516\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "alphas = [300,400,500,600,700] \n",
    "for i in alphas:\n",
    "    model_GBM= GradientBoostingClassifier(n_estimators=i,\n",
    "                                              random_state=0)\n",
    "    n_scores = cross_val_score(model_GBM, Norm_df_train, target, scoring='roc_auc', cv=5).mean()\n",
    "    print(n_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d8cb51d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=700, random_state=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GBM= GradientBoostingClassifier(n_estimators=i,\n",
    "                                              random_state=0)\n",
    "model_GBM.fit(Norm_df_train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae6677e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82146828, 0.89264176, 0.99951746, ..., 0.99886593, 0.9790729 ,\n",
       "       0.96157339])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2=model_GBM.predict_proba(Norm_df_test)\n",
    "y_newpred2=h2[:,1]\n",
    "y_newpred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7cab8036",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pred=0.3*y_newpred+0.4*y_newpred1+0.3*y_newpred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8e1e5300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87395097, 0.84167314, 0.99334384, ..., 0.99890681, 0.95724505,\n",
       "       0.93773639])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "17a41ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = pd.DataFrame({'id':test_ID,'Y':real_pred})\n",
    "output2.to_csv('rf+xgb1111.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
